{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    在学TF2之前，请忘记静态图！请忘记静态图！请忘记静态图！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "创建一个tensor\n",
    "\n",
    "tf2.0中可以直接看到numpy的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(), dtype=float64, numpy=2.0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(), dtype=string, numpy=b'hello world.'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant('hello world.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor放在cpu还是gpu?\n",
    "默认放在cpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('cpu'):\n",
    "    a = tf.constant([1])\n",
    "a\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('gpu'):\n",
    "    a = tf.range(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cpu gpu 互转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.gpu()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.cpu()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(3,), dtype=int32, numpy=array([0, 1, 2])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_numpy = a.numpy()\n",
    "a_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_numpy = int(a[0])\n",
    "type(a_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查tensor的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = tf.constant([1.])\n",
    "b = tf.constant([True, False])\n",
    "c = tf.constant('hello world')\n",
    "d = np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(a) # 推荐使用，原因tf.Variable()是tensor,但是isinstance 无法识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tf.Variable(1)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(e, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(e, tf.Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32, tf.bool, tf.string)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype, b.dtype, c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype == tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dtype == tf.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy 转tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=39, shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.convert_to_tensor(a)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(5,), dtype=float32, numpy=array([0., 1., 2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa =tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor 类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(5,), dtype=float64, numpy=array([0., 1., 2., 3., 4.])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = tf.cast(aa, dtype=tf.double)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45, shape=(2, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意dtype是float64\n",
    "tf.convert_to_tensor(np.ones([2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bool and int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=47, shape=(2,), dtype=int32, numpy=array([0, 1])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([0, 1])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=49, shape=(2,), dtype=bool, numpy=array([False,  True])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(b, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros([2,3])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=55, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros_like(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=59, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(1) # 这里的1 == [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=61, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([]) # 传scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=65, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "tf.ones([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.fill\n",
    "\n",
    "tensor填充想要的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=76, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[9, 9],\n",
       "       [9, 9]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2, 2], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=83, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.4151616 ,  0.75409603],\n",
       "       [-0.08040679,  0.6522907 ]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal([2, 2], mean=1, stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=90, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.33107063, -0.3921877 ],\n",
       "       [ 0.45560092, -0.41723162]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.truncated_normal([2, 2], mean=0, stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=98, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.04644084, 0.5306817 ],\n",
       "       [0.1573863 , 0.7957505 ]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform([2, 2], minval=0, maxval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.gather(a, idx)\n",
    "根据idx收集a中的一些数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  tf.Tensor([3 1 0 2], shape=(4,), dtype=int32)\n",
      "a:  tf.Tensor([3 7 9 4], shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=112, shape=(4,), dtype=int32, numpy=array([4, 7, 3, 9])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = tf.range(4)\n",
    "idx = tf.random.shuffle(idx)\n",
    "print('idx: ',idx)\n",
    "a = tf.random.uniform([4], maxval=10, dtype=tf.int32)\n",
    "print('a: ', a)\n",
    "aa = tf.gather(a, idx)\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=120, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.8271313 , 0.29440045, 0.9604119 , 0.33669078, 0.92162895,\n",
       "        0.32094002, 0.6888763 , 0.19028652, 0.1488576 , 0.01857793],\n",
       "       [0.34474874, 0.69677114, 0.94943976, 0.7805033 , 0.6940813 ,\n",
       "        0.10317683, 0.44957805, 0.5571593 , 0.32398295, 0.40015626],\n",
       "       [0.4643277 , 0.54785156, 0.39093208, 0.20444894, 0.52085173,\n",
       "        0.09884453, 0.5896226 , 0.4442371 , 0.03139639, 0.40095294],\n",
       "       [0.60203075, 0.48884344, 0.15060663, 0.04446554, 0.7103659 ,\n",
       "        0.62882423, 0.65154386, 0.9018471 , 0.26229584, 0.7680534 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络输出out [b, 10] = [4, 10]\n",
    "out = tf.random.uniform([4, 10])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=129, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label y [b] => [b, 10]\n",
    "y = tf.range(4)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=141, shape=(), dtype=float32, numpy=0.2969864>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.keras.losses.mse(y, out)\n",
    "loss = tf.reduce_mean(loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector and Matrix\n",
    "(bias and weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(8, 10) dtype=float32, numpy=\n",
       "array([[-0.4858433 ,  0.31981456,  0.13905162, -0.2508697 ,  0.48718548,\n",
       "         0.3147136 , -0.020688  ,  0.23889047, -0.31776863, -0.38435072],\n",
       "       [-0.44753584,  0.09830803, -0.3874122 ,  0.19779956, -0.28057835,\n",
       "        -0.1305975 , -0.3743531 , -0.5388241 ,  0.11132097, -0.40891936],\n",
       "       [-0.4636055 ,  0.5348172 , -0.01116514,  0.20384616,  0.509169  ,\n",
       "         0.12296736, -0.5292312 ,  0.22822553,  0.5637996 , -0.5340536 ],\n",
       "       [ 0.13152999, -0.3856101 , -0.20238584,  0.48257804,  0.5605731 ,\n",
       "         0.23294973,  0.3466277 , -0.34514165, -0.25734755,  0.15559578],\n",
       "       [-0.17090848,  0.04876798,  0.11940539, -0.317419  ,  0.33635497,\n",
       "         0.11153162, -0.11954924,  0.1721034 , -0.115978  , -0.2535225 ],\n",
       "       [-0.05159879,  0.3211978 , -0.38127628,  0.5421041 , -0.4980085 ,\n",
       "         0.29808962, -0.40836215, -0.05448616, -0.24131617, -0.10691038],\n",
       "       [ 0.543561  ,  0.1847862 ,  0.1657576 ,  0.02631366,  0.11849838,\n",
       "        -0.53927475, -0.50900805,  0.37538236,  0.46990705, -0.19109926],\n",
       "       [ 0.26428062, -0.27461657, -0.46487987, -0.5508801 , -0.05395877,\n",
       "        -0.4622338 , -0.20992595,  0.01165104, -0.48940006, -0.28862777]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = layers.Dense(10)\n",
    "net.build((4, 8))\n",
    "net.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([1,5,5,3])\n",
    "# python 风格的索引\n",
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=186, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 风格的索引\n",
    "a[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start:end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=191, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=201, shape=(2,), dtype=int32, numpy=array([1, 2])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=196, shape=(1,), dtype=int32, numpy=array([9])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1是最右边的索引  \n",
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=206, shape=(2,), dtype=int32, numpy=array([8, 9])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=211, shape=(9,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 除了最后一个都取\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([4, 28, 28, 3])\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 0, :, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start:end:step\n",
    "\n",
    "::step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(10)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=231, shape=(4,), dtype=int32, numpy=array([1, 3, 5, 7])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step=2\n",
    "a[1:8:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=236, shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::-1 翻转tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=241, shape=(10,), dtype=int32, numpy=array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([2, 4, 28, 28, 3])\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :, :, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, ...].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.gather  对一个维度获取值\n",
    "\n",
    "data: [classes, students, subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([4, 35, 8])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 35, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取某两个班级的所有学生的所有成绩\n",
    "tf.gather(a, axis=0, indices=[0, 1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.gather_nd 对多个维度获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([35, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(a, [0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(a, [0, 1, 2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=274, shape=(2, 8), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取[0, 0，:] 和 [1, 1, :]\n",
    "# shape [1,1,8] + [1,1,8] => [2, 8]\n",
    "tf.gather_nd(a, [[0, 0], [1, 1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=300, shape=(4, 4, 1), dtype=int32, numpy=\n",
       "array([[[5],\n",
       "        [6],\n",
       "        [2],\n",
       "        [4]],\n",
       "\n",
       "       [[8],\n",
       "        [0],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[3],\n",
       "        [5],\n",
       "        [5],\n",
       "        [7]],\n",
       "\n",
       "       [[7],\n",
       "        [9],\n",
       "        [4],\n",
       "        [3]]])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform([4, 4, 1], maxval=10, minval=0, dtype=tf.int32)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=309, shape=(2, 1), dtype=int32, numpy=\n",
       "array([[5],\n",
       "       [4]])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(b, [[0, 0], [3, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=255, shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1,1,1] + [1,1,1] + [1,1,1] =>[3]\n",
    "tf.gather_nd(a, [[0, 0, 0], [1,1,1],[3,3,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 35, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保留mask矩阵中True部分\n",
    "tf.boolean_mask(a, mask=[True, True, False, False], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=315, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([2,3])\n",
    "tf.boolean_mask(a, mask=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4, 28, 28, 3])\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.reshape(a, [4, -1]), [4, 28, 28, 3]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tf.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 2, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal((4, 3, 2, 1))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 3, 4])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认将维度倒置\n",
    "tf.transpose(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 1, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [4, 3, 2, 1] => [4, 3, 1, 2]\n",
    "tf.transpose(a, perm=[0, 1, 3, 2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "squeeae vs expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4, 35, 8])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 35, 8])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(a, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(a, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(tf.zeros([1,2,1,1,3])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.zeros([1,2,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.normal([1,4,35,8])\n",
    "tf.squeeze(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(b, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.squeeze(b, axis=-4).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broadcasting\n",
    "\n",
    "1、右对齐\n",
    "\n",
    "2、维度不一致，补齐（补1）\n",
    "\n",
    "3、将维度为1的那些轴扩充成两者中较长的维度\n",
    "\n",
    "ps:广播机制实现维度扩充并不会存储在内存或显存中，只是对计算的一个优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 32, 32, 3])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,32,32, 3])\n",
    "y = tf.random.normal([3])\n",
    "z = x + y\n",
    "z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 32, 32, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcast_to 原地更新（inplace）\n",
    "x = tf.broadcast_to(y, x.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broadcast vs tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=550, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([3, 4])\n",
    "a1 = tf.broadcast_to(a, [2, 3, 4])\n",
    "a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 4])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用tf.expand_dims 和tf.tile实现tf.broadcast功能\n",
    "# 区别： tf.tile会把扩展的值保存在内存中\n",
    "a2 = tf.expand_dims(a, axis=0)\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=555, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = tf.tile(a2, [2, 1, 1])\n",
    "a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学运算\n",
    "\n",
    "element-wise:  +-*/\n",
    "\n",
    "matrix-wise:   @  matmul\n",
    "\n",
    "dim-wise:    reduce_mean/max/min/sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [3 3]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 1]\n",
      " [1 1]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 2]\n",
      " [2 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.fill([2, 2], 2)\n",
    "b = tf.ones([2,2], dtype=tf.int32)\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=586, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 0]])>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 地板除\n",
    "b//a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.math.log\n",
    "\n",
    "tf.exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=572, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 2],\n",
       "       [2, 2]])>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=594, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[7.389056, 7.389056],\n",
       "       [7.389056, 7.389056]], dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.cast(a, dtype=tf.float32)\n",
    "tf.exp(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=596, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.6931472, 0.6931472],\n",
       "       [0.6931472, 0.6931472]], dtype=float32)>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=606, shape=(), dtype=float32, numpy=2.3025851>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log 以e为底数\n",
    "tf.math.log(10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=617, shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log2(8)实现:换底公式\n",
    "log_2 = tf.math.log(8.) / tf.math.log(2.)\n",
    "log_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=623, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log10(10)实现：\n",
    "log_10 = tf.math.log(100.) / tf.math.log(10.)\n",
    "log_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pow \n",
    "\n",
    "sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=631, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.fill([2,2], 2.)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=634, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[8., 8.],\n",
       "       [8., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pow(b, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=637, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[8., 8.],\n",
       "       [8., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=639, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.4142135, 1.4142135],\n",
       "       [1.4142135, 1.4142135]], dtype=float32)>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ == matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 2, 3)\n",
      "(4, 4, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([4, 4, 2, 3])\n",
    "b = tf.fill([4,4, 3, 5], 2.)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 2, 5])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @ 矩阵相乘，最后两维看作是一个矩阵的行和列 \n",
    "c = a@b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 2, 5])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.matmul(a, b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y = X @ W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=668, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[2.1],\n",
       "       [2.1],\n",
       "       [2.1],\n",
       "       [2.1]], dtype=float32)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones([4, 2])\n",
    "W = tf.ones([2, 1])\n",
    "b = tf.constant(0.1)\n",
    "x@W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=675, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[2.1],\n",
       "       [2.1],\n",
       "       [2.1],\n",
       "       [2.1]], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.relu(x@W+b)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random.truncated_normal([784, 512], stddev=0.1))\n",
    "tf.is_tensor(w1)\n",
    "b1 = tf.Variable(tf.zeros[512])\n",
    "for step, (x, y) in enumerate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hellow World in Deeplearning: MNIST\n",
    "\n",
    "1、加载数据\n",
    "\n",
    "2、训练：\n",
    "\n",
    "    前项\n",
    "    \n",
    "    loss\n",
    "    \n",
    "    计算梯度\n",
    "    \n",
    "    bp更新\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "# x: [60k, 28, 28]\n",
    "# y:[60k]\n",
    "(x, y), _ = datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# x[0-255] => [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28) (128,)\n"
     ]
    }
   ],
   "source": [
    "#将加载进来的数据打包成网络可用的batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.41730421781539917\n",
      "0 100 loss: 0.20625467598438263\n",
      "0 200 loss: 0.18165622651576996\n",
      "0 300 loss: 0.17070910334587097\n",
      "0 400 loss: 0.17376823723316193\n",
      "1 0 loss: 0.15751643478870392\n",
      "1 100 loss: 0.1607750654220581\n",
      "1 200 loss: 0.1503896862268448\n",
      "1 300 loss: 0.14429600536823273\n",
      "1 400 loss: 0.14638476073741913\n",
      "2 0 loss: 0.13458187878131866\n",
      "2 100 loss: 0.14115481078624725\n",
      "2 200 loss: 0.13245388865470886\n",
      "2 300 loss: 0.12659813463687897\n",
      "2 400 loss: 0.12872543931007385\n",
      "3 0 loss: 0.11911433935165405\n",
      "3 100 loss: 0.12767282128334045\n",
      "3 200 loss: 0.11997254192829132\n",
      "3 300 loss: 0.11415383964776993\n",
      "3 400 loss: 0.11628677695989609\n",
      "4 0 loss: 0.1080213338136673\n",
      "4 100 loss: 0.11773601919412613\n",
      "4 200 loss: 0.11073829978704453\n",
      "4 300 loss: 0.1050143837928772\n",
      "4 400 loss: 0.10700678825378418\n",
      "5 0 loss: 0.09960345178842545\n",
      "5 100 loss: 0.11008040606975555\n",
      "5 200 loss: 0.10364830493927002\n",
      "5 300 loss: 0.09804201126098633\n",
      "5 400 loss: 0.09982790052890778\n",
      "6 0 loss: 0.09306903183460236\n",
      "6 100 loss: 0.1040017381310463\n",
      "6 200 loss: 0.0980333462357521\n",
      "6 300 loss: 0.09255733340978622\n",
      "6 400 loss: 0.09410323947668076\n",
      "7 0 loss: 0.08780162036418915\n",
      "7 100 loss: 0.09904156625270844\n",
      "7 200 loss: 0.09338823705911636\n",
      "7 300 loss: 0.08807756006717682\n",
      "7 400 loss: 0.08947829157114029\n",
      "8 0 loss: 0.08346742391586304\n",
      "8 100 loss: 0.09489904344081879\n",
      "8 200 loss: 0.08949947357177734\n",
      "8 300 loss: 0.08433820307254791\n",
      "8 400 loss: 0.0856037363409996\n",
      "9 0 loss: 0.07981015741825104\n",
      "9 100 loss: 0.0913311094045639\n",
      "9 200 loss: 0.08617930114269257\n",
      "9 300 loss: 0.08117377758026123\n",
      "9 400 loss: 0.08236591517925262\n"
     ]
    }
   ],
   "source": [
    "# 网络参数初始化\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "lr = 1e-3\n",
    "\n",
    "for epoch in range(10):\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward\n",
    "            # [b, 784] => [b, 256]\n",
    "            h1 = x@w1 + b1\n",
    "            h1 = tf.nn.relu(h1)\n",
    "\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "\n",
    "            # [b, 128] => [b, 10]\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            out = h2@w3 + b3\n",
    "\n",
    "            # compute loss\n",
    "            # out :[b, 10]\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "\n",
    "            loss = tf.square(y_onehot - out)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # update\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])      \n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])   \n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss:', float(loss))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 35, 8])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([4, 35, 8])\n",
    "b = tf.ones([2, 35, 8])\n",
    "\n",
    "c = tf.concat([a, b], axis=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 35, 8)\n",
      "(2, 35, 8)\n"
     ]
    }
   ],
   "source": [
    "# tf.stack : 创造一个新的维度\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 2, 35, 8])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([4, 35, 8])\n",
    "b = tf.ones([4, 35, 8])\n",
    "\n",
    "c = tf.stack([a, b], axis=1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 35, 8)\n",
      "(4, 35, 8)\n"
     ]
    }
   ],
   "source": [
    "aa, bb = tf.unstack(c,axis=1)\n",
    "print(aa.shape)\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876366, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([2, 2])\n",
    "# 默认求L2范数\n",
    "tf.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876371, shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1范数\n",
    "tf.norm(a, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876376, shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 某一个轴的L1范数\n",
    "tf.norm(a, ord=1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce_min/max/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876385, shape=(10,), dtype=float32, numpy=\n",
       "array([-0.9367147 , -0.4399184 , -0.84076613, -0.4720565 , -1.9700844 ,\n",
       "       -1.1336707 , -1.9769382 , -1.5289234 , -0.9495128 , -0.2790423 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4, 10])\n",
    "# 所有数求平均\n",
    "tf.reduce_mean(a)\n",
    "# 按行求最大\n",
    "tf.reduce_max(a, axis=1)\n",
    "# 按列求最小\n",
    "tf.reduce_min(a, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argmax\n",
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认按列得到取值最大的索引\n",
    "b = tf.argmax(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3,4,5])\n",
    "b = tf.range(5)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876411, shape=(5,), dtype=bool, numpy=array([False, False, False, False, False])>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876424, shape=(2,), dtype=int32, numpy=array([2, 0])>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.constant([[0.1, 0.2, 0.7],\n",
    "                  [0.9, 0.05, 0.05]], dtype=tf.float32)\n",
    "\n",
    "pred = tf.cast(tf.argmax(out, axis=1), dtype=tf.int32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876464, shape=(), dtype=float64, numpy=0.5>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([2,1])\n",
    "\n",
    "correct = tf.reduce_sum(tf.cast(tf.equal(pred, y), tf.int32))\n",
    "print(correct)\n",
    "correct = correct / 2\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.unique\n",
    "\n",
    "tensor去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=876473, shape=(3,), dtype=int32, numpy=array([4, 2, 3])>,\n",
       " <tf.Tensor: id=876474, shape=(5,), dtype=int32, numpy=array([0, 1, 1, 0, 2])>)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([4, 2, 2,4,3])\n",
    "# 返回两个tensor， b :去重后的结果 c: 索引，可由此索引和b还原原来的数\n",
    "\n",
    "b, c = tf.unique(a)\n",
    "b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876487, shape=(1, 5), dtype=bool, numpy=array([[ True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = tf.gather(b, [c])\n",
    "tf.equal(a, a_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.sort\n",
    "\n",
    "tf.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876555, shape=(5,), dtype=int32, numpy=array([2, 4, 1, 0, 3])>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.shuffle(tf.range(5))\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876555, shape=(5,), dtype=int32, numpy=array([2, 4, 1, 0, 3])>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sort(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876580, shape=(5,), dtype=int32, numpy=array([3, 2, 0, 4, 1])>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876636, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[3, 7, 8],\n",
       "       [1, 3, 4],\n",
       "       [3, 4, 5]])>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform([3, 3], maxval=10, dtype=tf.int32)\n",
    "a = tf.sort(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876648, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2]])>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876636, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[3, 7, 8],\n",
       "       [1, 3, 4],\n",
       "       [3, 4, 5]])>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876681, shape=(3, 2), dtype=int32, numpy=\n",
       "array([[8, 7],\n",
       "       [4, 3],\n",
       "       [5, 4]])>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "res = tf.math.top_k(a, 2)\n",
    "res.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876663, shape=(3, 2), dtype=int32, numpy=\n",
       "array([[2, 1],\n",
       "       [2, 1],\n",
       "       [2, 1]])>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算top_k正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob: [[0.25310278 0.21715644 0.16043882 0.13088997 0.04334083 0.19507109]\n",
      " [0.05892418 0.04548917 0.00926314 0.14529602 0.66777605 0.07325139]\n",
      " [0.09742808 0.08304427 0.07460099 0.04067177 0.626185   0.07806987]\n",
      " [0.20478569 0.12294924 0.12010485 0.13751231 0.36418733 0.05046057]\n",
      " [0.11872064 0.31072393 0.12530336 0.1552888  0.2132587  0.07670452]\n",
      " [0.01519807 0.09672114 0.1460476  0.00934331 0.5649092  0.16778067]\n",
      " [0.04199061 0.18141054 0.06647632 0.6006175  0.03198383 0.07752118]\n",
      " [0.09226219 0.2346089  0.13022321 0.16295874 0.05362028 0.3263266 ]\n",
      " [0.07019574 0.0861177  0.10912605 0.10521299 0.2152082  0.4141393 ]\n",
      " [0.01882887 0.26597694 0.19122466 0.24109262 0.14920162 0.13367532]]\n",
      "pred: [0 4 4 4 1 4 3 5 5 1]\n",
      "label: [0 2 3 4 2 4 2 3 5 5]\n",
      "top-1-6 acc: [40.0, 40.0, 50.0, 70.0, 80.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2467)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    pred = tf.math.top_k(output, maxk).indices\n",
    "    pred = tf.transpose(pred, perm=[1, 0])\n",
    "    target_ = tf.broadcast_to(target, pred.shape)\n",
    "    # [10, b]\n",
    "    correct = tf.equal(pred, target_)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = tf.cast(tf.reshape(correct[:k], [-1]), dtype=tf.float32)\n",
    "        correct_k = tf.reduce_sum(correct_k)\n",
    "        acc = float(correct_k* (100.0 / batch_size) )\n",
    "        res.append(acc)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "output = tf.random.normal([10, 6])\n",
    "output = tf.math.softmax(output, axis=1)\n",
    "target = tf.random.uniform([10], maxval=6, dtype=tf.int32)\n",
    "print('prob:', output.numpy())\n",
    "pred = tf.argmax(output, axis=1)\n",
    "print('pred:', pred.numpy())\n",
    "print('label:', target.numpy())\n",
    "\n",
    "acc = accuracy(output, target, topk=(1,2,3,4,5,6))\n",
    "print('top-1-6 acc:', acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876785, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(9), [3,3])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876788, shape=(5, 4), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 1, 2],\n",
       "       [0, 3, 4, 5],\n",
       "       [0, 6, 7, 8],\n",
       "       [0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pad(a, [[1,1], [1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876785, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876792, shape=(3, 6), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 0, 1, 2],\n",
       "       [3, 4, 5, 3, 4, 5],\n",
       "       [6, 7, 8, 6, 7, 8]])>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.maximum(a, b) : 返回a,b中的最大值\n",
    "\n",
    "tf.minimum\n",
    "\n",
    "\n",
    "tf.clip_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876801, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876839, shape=(10,), dtype=int32, numpy=array([1, 7, 4, 5, 4, 7, 9, 9, 4, 3])>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform([10], minval=0, maxval=10, dtype=tf.int32)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876841, shape=(10,), dtype=int32, numpy=array([1, 7, 4, 5, 4, 7, 9, 9, 8, 9])>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.maximum(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876844, shape=(10,), dtype=int32, numpy=array([2, 2, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.maximum(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876847, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 3, 3, 3, 3, 3, 3])>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.minimum(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876852, shape=(10,), dtype=int32, numpy=array([2, 2, 2, 3, 4, 5, 6, 7, 8, 8])>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.clip_by_value(a, 2, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.clip_by_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876859, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 9.532964 , 10.01408  ],\n",
       "       [10.0157385,  9.255953 ]], dtype=float32)>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([2, 2], mean=10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876865, shape=(), dtype=float32, numpy=19.420269>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876883, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.454385 , 2.5782547],\n",
       "       [2.5786817, 2.383065 ]], dtype=float32)>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.clip_by_norm(a, 5)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=876889, shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 4.532197952270508\n",
      "100 loss: 0.6432369947433472\n",
      "200 loss: 0.3012292683124542\n",
      "300 loss: 0.4071490466594696\n",
      "400 loss: 0.43749818205833435\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "# [b, 28, 28, 3]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 127.5 - 1\n",
    "# [b] => [b, 10]\n",
    "y = tf.convert_to_tensor(y)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "\n",
    "# [b, 28, 28, 3]\n",
    "# [b, 10]\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "x, y = next(iter(train_db))\n",
    "# print(x.shape, y.shape)\n",
    "# 784 => 512\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 512], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([512]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([512, 256], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([256]))\n",
    "# [b, 10]\n",
    "w3 = tf.Variable(tf.random.truncated_normal([256, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "\n",
    "for step, (x,y) in enumerate(train_db):\n",
    "    x = tf.reshape(x, [-1, 784])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # layer1.\n",
    "        h1 = x @ w1 + b1\n",
    "        h1 = tf.nn.relu(h1)\n",
    "        # layer2\n",
    "        h2 = h1 @ w2 + b2\n",
    "        h2 = tf.nn.relu(h2)\n",
    "        # output\n",
    "        logit = h2 @ w3 + b3\n",
    "        # out = tf.nn.relu(out)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, logit, from_logits=True))\n",
    "        \n",
    "    # computer gradient\n",
    "    grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "    grads, _ = tf.clip_by_global_norm(grads, 5)\n",
    "    \n",
    "    # update\n",
    "    optimizer.apply_gradients(zip(grads, [w1, b1, w2, b2, w3, b3]))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, 'loss:', float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_tensor_slices()\n",
    "(x, y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "next(iter(db))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .shuffle\n",
    "db = db.shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([28, 28]), TensorShape([10]))"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .map\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32)/ 255.\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "db2 = db.map(preprocess)\n",
    "res = next(iter(db2))\n",
    "res[0].shape, res[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2883510, shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 28, 28]), TensorShape([32, 10]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .batch\n",
    "db3 = db2.batch(32)\n",
    "res = next(iter(db3))\n",
    "res[0].shape, res[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写一遍比较完整的mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss:  3.1128874\n",
      "78 Evaluate Acc: 0.09384889240506329\n",
      "0 100 loss:  1.0359747\n",
      "0 200 loss:  0.6256821\n",
      "0 300 loss:  0.6009066\n",
      "0 400 loss:  0.47016668\n",
      "1 0 loss:  0.4242708\n",
      "78 Evaluate Acc: 0.872626582278481\n",
      "1 100 loss:  0.4523915\n",
      "1 200 loss:  0.35190895\n",
      "1 300 loss:  0.40619582\n",
      "1 400 loss:  0.3366956\n",
      "2 0 loss:  0.29382175\n",
      "78 Evaluate Acc: 0.8958662974683544\n",
      "2 100 loss:  0.33402175\n",
      "2 200 loss:  0.30737653\n",
      "2 300 loss:  0.34209058\n",
      "2 400 loss:  0.28476316\n",
      "3 0 loss:  0.236809\n",
      "78 Evaluate Acc: 0.906942246835443\n",
      "3 100 loss:  0.26859537\n",
      "3 200 loss:  0.2910796\n",
      "3 300 loss:  0.3049006\n",
      "3 400 loss:  0.25388867\n",
      "4 0 loss:  0.20151255\n",
      "78 Evaluate Acc: 0.914754746835443\n",
      "4 100 loss:  0.22604337\n",
      "4 200 loss:  0.2810444\n",
      "4 300 loss:  0.27894944\n",
      "4 400 loss:  0.23238349\n",
      "5 0 loss:  0.17618316\n",
      "78 Evaluate Acc: 0.9181170886075949\n",
      "5 100 loss:  0.19604462\n",
      "5 200 loss:  0.2724632\n",
      "5 300 loss:  0.25895\n",
      "5 400 loss:  0.21576703\n",
      "6 0 loss:  0.15659714\n",
      "78 Evaluate Acc: 0.921875\n",
      "6 100 loss:  0.17376609\n",
      "6 200 loss:  0.26426974\n",
      "6 300 loss:  0.24132124\n",
      "6 400 loss:  0.2015292\n",
      "7 0 loss:  0.14072235\n",
      "78 Evaluate Acc: 0.9248417721518988\n",
      "7 100 loss:  0.15608238\n",
      "7 200 loss:  0.2562899\n",
      "7 300 loss:  0.22623038\n",
      "7 400 loss:  0.1893291\n",
      "8 0 loss:  0.1276011\n",
      "78 Evaluate Acc: 0.9279074367088608\n",
      "8 100 loss:  0.14163525\n",
      "8 200 loss:  0.24858223\n",
      "8 300 loss:  0.21299745\n",
      "8 400 loss:  0.17865777\n",
      "9 0 loss:  0.11634652\n",
      "78 Evaluate Acc: 0.9298852848101266\n",
      "9 100 loss:  0.12957346\n",
      "9 200 loss:  0.24088518\n",
      "9 300 loss:  0.2006047\n",
      "9 400 loss:  0.16916513\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, optimizers\n",
    "\n",
    "# 图像预处理\n",
    "def preprocess(x, y):\n",
    "    x = tf.reshape(x, [-1, 28*28])\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "# 导入数据:\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.shuffle(10000).batch(128).map(preprocess)\n",
    "#t1 = next(iter(train_db))\n",
    "#t1[0].shape, t1[1].shape\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.batch(128).map(preprocess)\n",
    "\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 512],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([512]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([512, 256],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([256]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([256, 10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "for epoch in range(10):\n",
    "    for step,(x, y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            h1 = x@w1 + b1\n",
    "            h1 = tf.nn.relu(h1)\n",
    "\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            logit = h2@w3 + b3\n",
    "\n",
    "            # compute loss\n",
    "            loss = tf.losses.categorical_crossentropy(y, logit, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            # compute grads\n",
    "            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        \n",
    "        # bp\n",
    "        optimizer.apply_gradients(zip(grads, [w1, b1, w2, b2, w3, b3]))\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss: ', loss.numpy())\n",
    "            \n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            total, total_correct = 0, 0\n",
    "            for step, (x_test, y_test) in enumerate(test_db):\n",
    "                \n",
    "                h1 = x_test@w1 + b1               \n",
    "                h1 = tf.nn.relu(h1)\n",
    "                h2 = h1@w2 + b2\n",
    "                h2 = tf.nn.relu(h2)\n",
    "                # [b, 10]\n",
    "                logit = h2@w3 + b3\n",
    "                \n",
    "                pred = tf.argmax(logit, axis=1)\n",
    "                # y [b, 10] => [b]\n",
    "                # print(y_test.shape)\n",
    "                y_test = tf.argmax(y_test, axis=1)\n",
    "                \n",
    "                correct = tf.cast(tf.equal(pred, y_test) , dtype=tf.int32)\n",
    "                correct = tf.reduce_sum(correct).numpy()\n",
    "                total_correct += correct\n",
    "                total += x.shape[0]\n",
    "                \n",
    "            print(step, 'Evaluate Acc:', total_correct/total)\n",
    "                \n",
    "                    \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 512])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4, 784])\n",
    "net = tf.keras.layers.Dense(512)\n",
    "out = net(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([784, 512]), TensorShape([512]))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.kernel.shape, net.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tf.keras.layers.Dense(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              multiple                  10        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  6         \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([2, 3])\n",
    "model = keras.Sequential([\n",
    "        keras.layers.Dense(2, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='relu'),\n",
    "        keras.layers.Dense(2)])\n",
    "\n",
    "model.build(input_shape=(None, 4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_5/kernel:0 (4, 2)\n",
      "dense_5/bias:0 (2,)\n",
      "dense_6/kernel:0 (2, 2)\n",
      "dense_6/bias:0 (2,)\n",
      "dense_7/kernel:0 (2, 2)\n",
      "dense_7/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "for p in model.trainable_variables:\n",
    "    print(p.name, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4699107, shape=(5,), dtype=float32, numpy=array([-2., -1.,  0.,  1.,  2.], dtype=float32)>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.linspace(-2., 2., 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4699109, shape=(5,), dtype=float32, numpy=\n",
       "array([0.11920291, 0.26894143, 0.5       , 0.7310586 , 0.880797  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4699111, shape=(5,), dtype=float32, numpy=\n",
       "array([0.01165623, 0.03168492, 0.08612854, 0.23412167, 0.6364086 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4699130, shape=(), dtype=float32, numpy=2.3025851>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.categorical_crossentropy([0,1,0, 0], [0.1,0.1,0.8, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4699184, shape=(), dtype=float32, numpy=1.4228988>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1,1,0],[0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=4699225, shape=(), dtype=float32, numpy=11.0>]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(2.)\n",
    "x = tf.constant(11.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w])\n",
    "    y = x * w\n",
    "grad = tape.gradient(y, [w])\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=4699517, shape=(), dtype=float32, numpy=2.0>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "#x = tf.Variable(1.)\n",
    "#w1 = tf.Variable(2.)\n",
    "#b1 = tf.Variable(1.)\n",
    "#w2 = tf.Variable(2.)\n",
    "#b2 = tf.Variable(1.)\n",
    "\n",
    "x = tf.constant(1.)\n",
    "w1 = tf.constant(2.)\n",
    "b1 = tf.constant(1.)\n",
    "w2 = tf.constant(2.)\n",
    "b2 = tf.constant(1.)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "    #tape.watch([w1, b1, w2, b2])\n",
    "    tape.watch([w1, b1, w2, b2])\n",
    "    \n",
    "    y1 = x * w1 + b1\n",
    "    y2 = y1 * w2 + b2\n",
    "\n",
    "dy2_dy1 = tape.gradient(y2, [y1])\n",
    "dy1_dw1 = tape.gradient(y1, [w1])\n",
    "dy2_dw1 = tape.gradient(y2, [w1])\n",
    "\n",
    "\n",
    "#print(dy2_dy1 * dy1_dw1)\n",
    "print(dy2_dw1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fashionMNIST实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "batch: (128, 28, 28) (128,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss: 2.3149633407592773 0.15233640372753143\n",
      "0 100 loss: 0.5193741917610168 14.602886199951172\n",
      "0 200 loss: 0.5342365503311157 18.514455795288086\n",
      "0 300 loss: 0.4424086809158325 16.391164779663086\n",
      "0 400 loss: 0.3993969261646271 21.030773162841797\n",
      "0 test acc: 0.8502\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential\n",
    "\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "(x, y), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "batchsz = 128\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db_test = db_test.map(preprocess).batch(batchsz)\n",
    "\n",
    "db_iter = iter(db)\n",
    "sample = next(db_iter)\n",
    "print('batch:', sample[0].shape, sample[1].shape)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu), # [b, 784] => [b, 256]\n",
    "    layers.Dense(128, activation=tf.nn.relu), # [b, 256] => [b, 128]\n",
    "    layers.Dense(64, activation=tf.nn.relu), # [b, 128] => [b, 64]\n",
    "    layers.Dense(32, activation=tf.nn.relu), # [b, 64] => [b, 32]\n",
    "    layers.Dense(10) # [b, 32] => [b, 10], 330 = 32*10 + 10\n",
    "])\n",
    "model.build(input_shape=[None, 28*28])\n",
    "model.summary()\n",
    "# w = w - lr*grad\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    for epoch in range(1):\n",
    "\n",
    "\n",
    "        for step, (x,y) in enumerate(db):\n",
    "\n",
    "            # x: [b, 28, 28] => [b, 784]\n",
    "            # y: [b]\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 784] => [b, 10]\n",
    "                logits = model(x)\n",
    "                y_onehot = tf.one_hot(y, depth=10)\n",
    "                # [b]\n",
    "                loss_mse = tf.reduce_mean(tf.losses.MSE(y_onehot, logits))\n",
    "                loss_ce = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss_ce = tf.reduce_mean(loss_ce)\n",
    "\n",
    "            grads = tape.gradient(loss_ce, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(epoch, step, 'loss:', float(loss_ce), float(loss_mse))\n",
    "\n",
    "\n",
    "        # test\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for x,y in db_test:\n",
    "\n",
    "            # x: [b, 28, 28] => [b, 784]\n",
    "            # y: [b]\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # [b, 10]\n",
    "            logits = model(x)\n",
    "            # logits => prob, [b, 10]\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            # [b, 10] => [b], int64\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # pred:[b]\n",
    "            # y: [b]\n",
    "            # correct: [b], True: equal, False: not equal\n",
    "            correct = tf.equal(pred, y)\n",
    "            correct = tf.reduce_sum(tf.cast(correct, dtype=tf.int32))\n",
    "\n",
    "            total_correct += int(correct)\n",
    "            total_num += x.shape[0]\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, 'test acc:', acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、建立一个summary\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir\n",
    "\n",
    "2、喂scalar\n",
    "\n",
    "with summary_writer.as_default():\n",
    "\n",
    "    tf.summary.scalar('loss', float(loss), step=epoch)\n",
    "    \n",
    "    tf.summary.scalar('acc',float(train_accurary),step=epoch)\n",
    "    \n",
    "3、喂image\n",
    "\n",
    "    tf.summary.image('Training sample', sample_img, step=0)\n",
    "\n",
    "4、run: tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.277104616165161\n",
      "0 Evaluate Acc: 0.1877003205128205\n",
      "100 loss: 0.22898100316524506\n",
      "200 loss: 0.29720965027809143\n",
      "300 loss: 0.22308921813964844\n",
      "400 loss: 0.21488501131534576\n",
      "500 loss: 0.0969645082950592\n",
      "500 Evaluate Acc: 0.9621394230769231\n",
      "600 loss: 0.17301949858665466\n",
      "700 loss: 0.17734237015247345\n",
      "800 loss: 0.1251913160085678\n",
      "900 loss: 0.0713217481970787\n",
      "1000 loss: 0.12768054008483887\n",
      "1000 Evaluate Acc: 0.9628405448717948\n",
      "1100 loss: 0.21235521137714386\n",
      "1200 loss: 0.10854841768741608\n",
      "1300 loss: 0.03802848979830742\n",
      "1400 loss: 0.08516974747180939\n",
      "1500 loss: 0.09374243766069412\n",
      "1500 Evaluate Acc: 0.965645032051282\n",
      "1600 loss: 0.19635231792926788\n",
      "1700 loss: 0.09235326945781708\n",
      "1800 loss: 0.021013423800468445\n",
      "1900 loss: 0.04309888556599617\n",
      "2000 loss: 0.13101541996002197\n",
      "2000 Evaluate Acc: 0.9698517628205128\n",
      "2100 loss: 0.06076184660196304\n",
      "2200 loss: 0.12495772540569305\n",
      "2300 loss: 0.031704261898994446\n",
      "2400 loss: 0.027352359145879745\n",
      "2500 loss: 0.06144028529524803\n",
      "2500 Evaluate Acc: 0.9688501602564102\n",
      "2600 loss: 0.09702807664871216\n",
      "2700 loss: 0.00874280370771885\n",
      "2800 loss: 0.08580313622951508\n",
      "2900 loss: 0.13154348731040955\n",
      "3000 loss: 0.02960415557026863\n",
      "3000 Evaluate Acc: 0.9717548076923077\n",
      "3100 loss: 0.03901351988315582\n",
      "3200 loss: 0.03642797842621803\n",
      "3300 loss: 0.058610185980796814\n",
      "3400 loss: 0.020462878048419952\n",
      "3500 loss: 0.09511932730674744\n",
      "3500 Evaluate Acc: 0.9673477564102564\n",
      "3600 loss: 0.12187643349170685\n",
      "3700 loss: 0.13361547887325287\n",
      "3800 loss: 0.04291796311736107\n",
      "3900 loss: 0.060058221220970154\n",
      "4000 loss: 0.07773319631814957\n",
      "4000 Evaluate Acc: 0.9663461538461539\n",
      "4100 loss: 0.08248505741357803\n",
      "4200 loss: 0.17281658947467804\n",
      "4300 loss: 0.012307697907090187\n",
      "4400 loss: 0.004092834889888763\n",
      "4500 loss: 0.007367650978267193\n",
      "4500 Evaluate Acc: 0.9691506410256411\n",
      "4600 loss: 0.015582036226987839\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import  datetime\n",
    "from    matplotlib import pyplot as plt\n",
    "import  io\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid(images):\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title='name')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "  \n",
    "  return figure\n",
    "\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz, drop_remainder=True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir) \n",
    "\n",
    "# get x from (x,y)\n",
    "sample_img = next(iter(db))[0]\n",
    "# get first image instance\n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample:\", sample_img, step=0)\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    " \n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', float(loss))\n",
    "        with summary_writer.as_default(): \n",
    "            tf.summary.scalar('train-loss', float(loss), step=step) \n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "\n",
    "        for _, (x, y) in enumerate(ds_val):  \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total)\n",
    "\n",
    "        \n",
    "        # print(x.shape) \n",
    "        val_images = x[:25]\n",
    "        val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('test-acc', float(total_correct/total), step=step)\n",
    "            tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "            val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "            figure  = image_grid(val_images)\n",
    "            tf.summary.image('val-images:', plot_to_image(figure), step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras.Metrics\n",
    "\n",
    "1、定义一把尺子\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "2、训练或测试过程中不断更新\n",
    "\n",
    "loss_meter.update_state(loss)\n",
    "\n",
    "acc_meter.update_state(y, pred)\n",
    "\n",
    "3、输出结果(输出的是开始记录以来的平均值)\n",
    "\n",
    "\n",
    "loss_meter.result().numpy()\n",
    "\n",
    "\n",
    "acc_meter.result().numpy()\n",
    "\n",
    "\n",
    "4、 如果原来的记录不要了的话，记得清空\n",
    "\n",
    "reset_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.3416376\n",
      "78 Evaluate Acc: 0.1076 0.1076\n",
      "100 loss: 0.54802066\n",
      "200 loss: 0.23968677\n",
      "300 loss: 0.19421378\n",
      "400 loss: 0.18152523\n",
      "500 loss: 0.1540474\n",
      "78 Evaluate Acc: 0.9556 0.9556\n",
      "600 loss: 0.13989474\n",
      "700 loss: 0.14793208\n",
      "800 loss: 0.11889808\n",
      "900 loss: 0.13163692\n",
      "1000 loss: 0.120461114\n",
      "78 Evaluate Acc: 0.9586 0.9586\n",
      "1100 loss: 0.12576473\n",
      "1200 loss: 0.12135755\n",
      "1300 loss: 0.117579214\n",
      "1400 loss: 0.0979012\n",
      "1500 loss: 0.09202363\n",
      "78 Evaluate Acc: 0.9601 0.9601\n",
      "1600 loss: 0.09795978\n",
      "1700 loss: 0.103510514\n",
      "1800 loss: 0.099560596\n",
      "1900 loss: 0.08892284\n",
      "2000 loss: 0.07449369\n",
      "78 Evaluate Acc: 0.9698 0.9698\n",
      "2100 loss: 0.090514794\n",
      "2200 loss: 0.08641652\n",
      "2300 loss: 0.08148347\n",
      "2400 loss: 0.0645952\n",
      "2500 loss: 0.07519101\n",
      "78 Evaluate Acc: 0.9698 0.9698\n",
      "2600 loss: 0.07798528\n",
      "2700 loss: 0.07776409\n",
      "2800 loss: 0.08355696\n",
      "2900 loss: 0.06870126\n",
      "3000 loss: 0.06972808\n",
      "78 Evaluate Acc: 0.9706 0.9706\n",
      "3100 loss: 0.06652368\n",
      "3200 loss: 0.06530569\n",
      "3300 loss: 0.08288539\n",
      "3400 loss: 0.06515466\n",
      "3500 loss: 0.0719689\n",
      "78 Evaluate Acc: 0.9705 0.9705\n",
      "3600 loss: 0.07511794\n",
      "3700 loss: 0.07478294\n",
      "3800 loss: 0.07708419\n",
      "3900 loss: 0.06773274\n",
      "4000 loss: 0.07668789\n",
      "78 Evaluate Acc: 0.9687 0.9687\n",
      "4100 loss: 0.111578986\n",
      "4200 loss: 0.07809682\n",
      "4300 loss: 0.06594393\n",
      "4400 loss: 0.06951174\n",
      "4500 loss: 0.057468735\n",
      "78 Evaluate Acc: 0.9702 0.9702\n",
      "4600 loss: 0.0782716\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    "        loss_meter.update_state(loss)\n",
    "\n",
    " \n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', loss_meter.result().numpy()) \n",
    "        loss_meter.reset_states()\n",
    "\n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        acc_meter.reset_states()\n",
    "\n",
    "        for step, (x, y) in enumerate(ds_val): \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "\n",
    "\n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "            acc_meter.update_state(y, pred)\n",
    "\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total, acc_meter.result().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 风格的训练，验证过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "(128, 784) (128, 10)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2874 - acc: 0.8323\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1371 - acc: 0.9593 - val_loss: 0.1458 - val_acc: 0.9589\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1164 - acc: 0.9661\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0977 - acc: 0.9742 - val_loss: 0.1215 - val_acc: 0.9698\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0840 - acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec3d7d7400>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential,  metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    x is a simple image, not a batch\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz) \n",
    "\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "# compile\n",
    "network.compile(optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['acc'])\n",
    "\n",
    "# train\n",
    "# network.fit包含了network.bulid的功能，参数初始化\n",
    "network.fit(db, epochs=5, validation_data=ds_val, validation_freq=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mymodel_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_dense_36 (MyDense)        multiple                  200960    \n",
      "_________________________________________________________________\n",
      "my_dense_37 (MyDense)        multiple                  32896     \n",
      "_________________________________________________________________\n",
      "my_dense_38 (MyDense)        multiple                  8256      \n",
      "_________________________________________________________________\n",
      "my_dense_39 (MyDense)        multiple                  2080      \n",
      "_________________________________________________________________\n",
      "my_dense_40 (MyDense)        multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable('w', [inp_dim, outp_dim])\n",
    "        self.bias = self.add_variable('b', [outp_dim])\n",
    "        \n",
    "    def call(self, inputs , training=None):\n",
    "        out = inputs @ self.kernel + self.bias\n",
    "        return out\n",
    "\n",
    "#mylayer = MyDense(4,3)\n",
    "#inputs = tf.ones([2,4])\n",
    "#out = mylayer(inputs)\n",
    "#out\n",
    "\n",
    "class Mymodel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Mymodel, self).__init__()\n",
    "        self.fc1 = MyDense(28*28, 256)\n",
    "        self.fc2 = MyDense(256,128)\n",
    "        self.fc3 = MyDense(128,64)\n",
    "        self.fc4 = MyDense(64,32)\n",
    "        self.fc5 = MyDense(32,10)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "            x = self.fc1(inputs)\n",
    "            x = tf.nn.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            x = tf.nn.relu(x)\n",
    "            x = self.fc3(x)\n",
    "            x = tf.nn.relu(x)\n",
    "            x = self.fc4(x)\n",
    "            x = tf.nn.relu(x)\n",
    "            x = self.fc5(x) \n",
    "\n",
    "            return x\n",
    "\n",
    "network = Mymodel()  \n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "        loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "network.build(input_shape=(4, 784))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "(128, 784) (128, 10)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2639 - accuracy: 0.8546\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1421 - accuracy: 0.9561 - val_loss: 0.1445 - val_accuracy: 0.9617\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1093 - accuracy: 0.9688\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0963 - accuracy: 0.9728 - val_loss: 0.1218 - val_accuracy: 0.9690\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0887 - accuracy: 0.9766\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9647\n",
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 6 7 6 7 9 0 5], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "from \ttensorflow import keras\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    x is a simple image, not a batch\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz) \n",
    "\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "\n",
    "\tdef __init__(self, inp_dim, outp_dim):\n",
    "\t\tsuper(MyDense, self).__init__()\n",
    "\n",
    "\t\tself.kernel = self.add_variable('w', [inp_dim, outp_dim])\n",
    "\t\tself.bias = self.add_variable('b', [outp_dim])\n",
    "\n",
    "\tdef call(self, inputs, training=None):\n",
    "\n",
    "\t\tout = inputs @ self.kernel + self.bias\n",
    "\n",
    "\t\treturn out \n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(MyModel, self).__init__()\n",
    "\n",
    "\t\tself.fc1 = MyDense(28*28, 256)\n",
    "\t\tself.fc2 = MyDense(256, 128)\n",
    "\t\tself.fc3 = MyDense(128, 64)\n",
    "\t\tself.fc4 = MyDense(64, 32)\n",
    "\t\tself.fc5 = MyDense(32, 10)\n",
    "\n",
    "\tdef call(self, inputs, training=None):\n",
    "\n",
    "\t\tx = self.fc1(inputs)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\tx = self.fc4(x)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\tx = self.fc5(x) \n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "network = MyModel()\n",
    "\n",
    "\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "\t\tloss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "\t\tmetrics=['accuracy']\n",
    "\t)\n",
    "\n",
    "network.fit(db, epochs=5, validation_data=ds_val,\n",
    "              validation_freq=2)\n",
    " \n",
    "network.evaluate(ds_val)\n",
    "\n",
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1] # one-hot\n",
    "pred = network.predict(x) # [b, 10]\n",
    "# convert back to number \n",
    "y = tf.argmax(y, axis=1)\n",
    "pred = tf.argmax(pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (128, 32, 32, 3) (128,) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from    tensorflow.keras import layers, optimizers, datasets, Sequential\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "(x,y), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print('sample:', sample[0].shape, sample[1].shape,\n",
    "      tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basenet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"fc_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  12900     \n",
      "=================================================================\n",
      "Total params: 177,124\n",
      "Trainable params: 177,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss:  4.605030059814453\n",
      "0 100 loss:  4.567522048950195\n",
      "0 200 loss:  4.338274955749512\n",
      "0 300 loss:  4.269405364990234\n",
      "0 acc: 0.0623\n",
      "1 0 loss:  4.123151779174805\n",
      "1 100 loss:  4.045558929443359\n",
      "1 200 loss:  3.9980111122131348\n",
      "1 300 loss:  3.9538023471832275\n",
      "1 acc: 0.1068\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "class Basenet(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Basenet, self).__init__()\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,  kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.conv2 = layers.Conv2D(64,  kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.maxpool1 = layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.maxpool2 = layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.maxpool3 = layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "        \n",
    "        self.conv7 = layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.conv8 = layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.maxpool4 = layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "        \n",
    "        self.conv9 = layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.conv10 = layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)        \n",
    "        self.maxpool5 = layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    # forward\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.conv1(inputs)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.maxpool4(x)\n",
    "\n",
    "        \n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.maxpool5(x)        \n",
    "        \n",
    "        return x\n",
    "\n",
    "conv_network = Basenet()\n",
    "conv_network.build(input_shape=(None,32,32,3))\n",
    "conv_network.summary()\n",
    "\n",
    "\n",
    "class fcNet(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(fcNet, self).__init__()\n",
    "        \n",
    "        self.dense1 = layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.dense2 = layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.dense3 = layers.Dense(100)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "fc_network = fcNet()\n",
    "fc_network.build(input_shape=(None, 512))\n",
    "fc_network.summary()\n",
    "\n",
    "\n",
    "# tf风格写法\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "variable = conv_network.trainable_variables + fc_network.trainable_variables\n",
    "\n",
    "for epoch in range(2):\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = conv_network(x)\n",
    "            #print(out)\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            logits = fc_network(out)\n",
    "            \n",
    "            y_onehot = tf.one_hot(y, depth=100)\n",
    "            # compute loss\n",
    "            loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)            \n",
    "        grads = tape.gradient(loss, variable)\n",
    "        optimizer.apply_gradients(zip(grads, variable))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss: ', float(loss))\n",
    "            \n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    for x,y in test_db:\n",
    "\n",
    "        out = conv_network(x)\n",
    "        out = tf.reshape(out, [-1, 512])\n",
    "        logits = fc_network(out)\n",
    "        prob = tf.nn.softmax(logits, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "\n",
    "        total_num += x.shape[0]\n",
    "        total_correct += int(correct)\n",
    "\n",
    "    acc = total_correct / total_num\n",
    "    print(epoch, 'acc:', acc)            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
